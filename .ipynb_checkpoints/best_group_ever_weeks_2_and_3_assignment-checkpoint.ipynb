{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlqVBEfLBOF_"
   },
   "source": [
    "**SOW-MKI49: Neural Information Processing Systems**  \n",
    "*Weeks 2 and 3: Assignment (200 points + 20 bonus points + 1 bonus point for each bug you find and another bonus point if you debug it and before you ask, no, typos unfortunately are not considered bugs - first come, first served)*  \n",
    "Author: Umut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rT8BaKk5CpeB"
   },
   "outputs": [],
   "source": [
    "# Group number: 24\n",
    "# Franka Buytenhuijs, s4356845\n",
    "# Hugo Chateau-Laurent, s1023970\n",
    "# Maria Tsfasman, s1021505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00iIAIv37Del"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "data_directory = './resized_data/'  # Make a directory to store the data and enter it here.\n",
    "                    # We will be using a smaller dataset (LFW) than the one used in the paper (CelebA) for computational resource considerations.\n",
    "                    # Download it from http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz.\n",
    "device = -1\n",
    "epochs = 100\n",
    "lambda_ = {'feature': 1., 'pixel': 1., 'total_variation': 1e-5}\n",
    "model_directory = './models' # Make a directory to store the models and enter it here. Move Vgg4Layers.npz to the model directory.\n",
    "outsize = (96, 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86zZctPu1K2M"
   },
   "source": [
    "**Packages (10 points)**  \n",
    "In this cell, you will import the required packages.  \n",
    "*Tasks*   \n",
    "- (1) It is always good practice to first think about the big picture and not rush into writing code before clearly knowing everything that you will have to do so as to avoid future complications. Therefore, your first task is to study the skeleton code and come up with a plan of how to proceed. (**0 points**)\n",
    "- (2) However, I agree that doing so is arguably the most boring part of coding, and you rather skip it. To help you to resist the temptation of skipping going through the skeleton code, I have removed the import statements. Your second task is to Identify the required packages and import them. Note that if you are using Python 2.7, you should import print from the future. (**10 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBiJw5pV030o"
   },
   "outputs": [],
   "source": [
    "# (2) start\n",
    "import chainer\n",
    "from chainer import Chain, ChainList\n",
    "from chainer.optimizers import Adam\n",
    "from chainer import iterators\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from glob import glob\n",
    "from chainer.serializers import load_npz, save_npz\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "from chainer.dataset import concat_examples\n",
    "from matplotlib import pyplot as plt\n",
    "from chainer.dataset import DatasetMixin\n",
    "# (2) end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOhjvsOx9lJY"
   },
   "source": [
    "**Preprocessing functions (10 points + 5 bonus points)** (taken from https://github.com/mbeyeler/opencv-python-blueprints)  \n",
    "In the following cell, you will implement some of the preprocessing functions. The rest of the preprocessing steps have already been applied to the data.  \n",
    "*Tasks*\n",
    "- (1) Implement the resizing operation. That is, you should extract the data, resize each portrait to 96 pixels x 96 pixels and save them to the data directory as JPG. (**10 points **)\n",
    "- (2) The pencil sketch class implements the sketch effect in a simpler way than the one mentioned in the lecture. Explain how/why the used operations (blur and divide) convert portraits to sketches, and how it differs from that which was mentioned in the lecture? (**5 bonus points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images():\n",
    "    data = []\n",
    "    files = glob.glob('./data/*/*.jpg')\n",
    "    \n",
    "    for index, file in enumerate(files):\n",
    "        new = file.replace('\\\\', '/')\n",
    "        read_img = cv2.imread(new)\n",
    "        resized_image = cv2.resize(read_img, outsize) \n",
    "        cv2.imwrite((data_directory + str(index) + '.jpg'), resized_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iY4lbpLK9kp4"
   },
   "outputs": [],
   "source": [
    "# (1) start\n",
    "# .\n",
    "# (1) end\n",
    "\n",
    "\n",
    "    \n",
    "class PencilSketch:\n",
    "    \"\"\"Pencil sketch effect\n",
    "        A class that applies a pencil sketch effect to an image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dimension, bg_gray='pencilsketch_bg.jpg'):\n",
    "        \"\"\"Initialize paramete\n",
    "            :param dimensions: Image size (width and height).\n",
    "        \"\"\"\n",
    "        self.width, self.height = dimension\n",
    "\n",
    "    def render(self, img_rgb):\n",
    "        \"\"\"Applies pencil sketch effect to an RGB image\n",
    "            :param img_rgb: RGB image to be processed\n",
    "            :returns: Processed RGB image\n",
    "        \"\"\"\n",
    "        img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        img_blur = cv2.GaussianBlur(img_gray, (21, 21), 0, 0)\n",
    "        img_blend = cv2.divide(img_gray, img_blur, scale=256)\n",
    "\n",
    "        # return cv2.cvtColor(img_blend, cv2.COLOR_GRAY2RGB)\n",
    "        return img_blend\n",
    "\n",
    "def pencil_sketch(img_rgb):\n",
    "    pencilSketch = PencilSketch((img_rgb.shape[1], img_rgb.shape[0]))\n",
    "\n",
    "    return pencilSketch.render(img_rgb)\n",
    "\n",
    "# (2) Write your answer here.\n",
    "\n",
    "def preprocess(img):\n",
    "    if img.mode == 'L':\n",
    "        return np.rollaxis(np.asarray(img, 'float32')[..., None], 2)\n",
    "    else:\n",
    "        return np.rollaxis(np.asarray(img, 'float32')[..., ::-1], 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "sketch_test = False # if you want to compute the sketched imgs\n",
    "\n",
    "if(sketch_test):\n",
    "    files = glob('./resized_data/*.jpg')\n",
    "    data_directory = './sketched_data/'  # Make a directory to store the data and enter it here.\n",
    "\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    for index, file in enumerate(files):\n",
    "        new = file.replace('\\\\', '/')\n",
    "        read_img = cv2.imread(new)\n",
    "        sketched = pencil_sketch(read_img)\n",
    "        cv2.imwrite((data_directory + str(index) + '.jpg'), sketched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovQMUuo_7D2k"
   },
   "source": [
    "**Data class**  \n",
    "The following cell defines the data class. It is used to manage the data (loading, etc.). *You do not have to make any changes to the code.*  \n",
    "*Task*\n",
    "- (1) Study the code and refer to the chainer documentation if anything is unclear. You will be expected to write similar code by yourself in the coming practicals. (**0 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OF39paH6wff"
   },
   "outputs": [],
   "source": [
    "class Dataset(DatasetMixin):\n",
    "    def __init__(self, data_files):\n",
    "        self.data_files = data_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        t = np.asarray(Image.open(self.data_files[i]).convert('RGB').resize((96, 96), Image.LANCZOS), 'f').transpose(2, 0, 1)\n",
    "        x = pencil_sketch(np.asarray((Image.open(self.data_files[i]).convert('RGB').resize((96, 96), Image.LANCZOS)), 'f'))[None]\n",
    "        return t, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUjEFdDD6xBq"
   },
   "source": [
    "**Model classes (45 points)**  \n",
    "In the following cellyou will implement the model classes.\n",
    "*Tasks*   \n",
    "- (1) Implement the layers of the model by filling in the missing code. (**20 points**)\n",
    "- (2) Reimplement the model as a ChainList instead of a Chain. (**5 points**)\n",
    "- (3) Implement the forward pass of the residual block by filling in the missing code. (**20 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nafY2Wgx6QLt"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "class Model(Chain):\n",
    "    def __init__(self, in_channels, outsize):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            \n",
    "            # (1) start\n",
    "            self.convolution2D_0 = L.Convolution2D(in_channels = in_channels, out_channels = 32, ksize = 9, stride = 1, pad = 4, nobias = True)\n",
    "            self.batchNormalization_0 = L.BatchNormalization(32)\n",
    "            self.convolution2D_1 = L.Convolution2D(in_channels = 32, out_channels = 64, ksize = 3, stride = 2, pad = 1, nobias = True)\n",
    "            self.batchNormalization_1 = L.BatchNormalization(64)\n",
    "            self.convolution2D_2 = L.Convolution2D(in_channels = 64, out_channels = 128, ksize = 3, stride = 2, pad = 1, nobias = True)\n",
    "            self.batchNormalization_2 = L.BatchNormalization(128)\n",
    "            self.residualBlock_3 =  ResidualBlock(128, 128)\n",
    "            self.residualBlock_4 = ResidualBlock(128, 128) \n",
    "            self.residualBlock_5 = ResidualBlock(128, 128) \n",
    "            self.residualBlock_6 = ResidualBlock(128, 128) \n",
    "            self.residualBlock_7 = ResidualBlock(128, 128) \n",
    "            self.deconvolution2D_8 = L.Deconvolution2D(in_channels = 128, out_channels = 64, ksize = 3, stride = 2, pad = 1, nobias = True)\n",
    "            self.batchNormalization_8 = L.BatchNormalization(64)\n",
    "            # (1) end\n",
    "            \n",
    "            self.deconvolution2D_9 = L.Deconvolution2D(64, 32, 3, 2, 1, True, outsize)\n",
    "            self.batchNormalization_9 = L.BatchNormalization(32)\n",
    "            self.convolution2D_10 = L.Convolution2D(32, 3, 9, pad = 4, nobias = True)\n",
    "            self.batchNormalization_10 = L.BatchNormalization(3)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.outsize = outsize\n",
    "\n",
    "    def __call__(self, x, finetune = False):\n",
    "        h = self.convolution2D_0(x)\n",
    "        h = self.batchNormalization_0(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_1(h)\n",
    "        h = self.batchNormalization_1(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_2(h)\n",
    "        h = self.batchNormalization_2(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.residualBlock_3(h, finetune)\n",
    "        h = self.residualBlock_4(h, finetune)\n",
    "        h = self.residualBlock_5(h, finetune)\n",
    "        h = self.residualBlock_6(h, finetune)\n",
    "        h = self.residualBlock_7(h, finetune)\n",
    "        h = self.deconvolution2D_8(h)\n",
    "        h = self.batchNormalization_8(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.deconvolution2D_9(h)\n",
    "        h = self.batchNormalization_9(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_10(h)\n",
    "        h = self.batchNormalization_10(h, finetune)\n",
    "        y = 127.5 * F.tanh(h) + 127.5\n",
    "\n",
    "        return y\n",
    "'''\n",
    "\n",
    "# (2) start\n",
    "class Model(ChainList):\n",
    "    \n",
    "    def __init__(self, in_channels, outsize):        \n",
    "        super(Model, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.outsize = outsize\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.append(Convolution2DBlock(in_channels, 32, 9, 1, 4, True))\n",
    "            self.append(Convolution2DBlock(32, 64, 3, 2, 1, True))\n",
    "            self.append(Convolution2DBlock(64, 128, 3, 2, 1, True))\n",
    "            self.append(ResidualBlock(128, 128))\n",
    "            self.append(ResidualBlock(128, 128))\n",
    "            self.append(ResidualBlock(128, 128))\n",
    "            self.append(ResidualBlock(128, 128))\n",
    "            self.append(ResidualBlock(128, 128))\n",
    "            self.append(Convolution2DBlock(128, 64, 3, 2, 1, True, deconv=True, outsize=outsize))\n",
    "            self.append(Convolution2DBlock(64, 32, 3, 2, 1, True, deconv=True, outsize=outsize))\n",
    "            self.append(Convolution2DBlock(32, 3, 9, 1, 4, True, relu=False))\n",
    "\n",
    "            \n",
    "            \n",
    "    def __call__(self, x, finetune = False):\n",
    "        h = x\n",
    "        for i in range(self.__len__()):\n",
    "            h = self.__getitem__(i)(h, finetune=finetune)\n",
    "        y = 127.5 * F.tanh(h) + 127.5\n",
    "        \n",
    "        return y\n",
    "    \n",
    "class Convolution2DBlock(ChainList):\n",
    "    def __init__(self, in_channels, out_channels, ksize, stride, pad, nobias = False, deconv=False, relu=True, outsize=None):\n",
    "        super(Convolution2DBlock, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            if deconv:\n",
    "                self.append(L.Deconvolution2D(in_channels, out_channels, ksize, stride, pad, nobias, outsize=outsize))\n",
    "            else:\n",
    "                self.append(L.Convolution2D(in_channels, out_channels, ksize, stride, pad, nobias))\n",
    "\n",
    "            self.append(L.BatchNormalization(out_channels))\n",
    "        \n",
    "        self.relu=relu\n",
    "        \n",
    "    def __call__(self, x, finetune = False):\n",
    "        h = x\n",
    "        for i in range(self.__len__()):\n",
    "            try:\n",
    "                h = self.__getitem__(i)(h, finetune=finetune)\n",
    "            except TypeError:\n",
    "                h = self.__getitem__(i)(h)\n",
    "        if self.relu:\n",
    "            h = F.relu(h)\n",
    "        return h\n",
    "# (2) end\n",
    "\n",
    "\n",
    "    \n",
    "class ResidualBlock(Chain):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.batchNormalization_0 = L.BatchNormalization(out_channels)\n",
    "            self.batchNormalization_1 = L.BatchNormalization(out_channels)\n",
    "            self.convolution2D_0 = L.Convolution2D( in_channels, out_channels, 3, pad = 1, nobias = True)\n",
    "            self.convolution2D_1 = L.Convolution2D(out_channels, out_channels, 3, pad = 1, nobias = True)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def __call__(self, x, finetune = False):\n",
    "        h = self.convolution2D_0(x)\n",
    "        h = self.batchNormalization_0(h, finetune=finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_1(h)\n",
    "        h = self.batchNormalization_1(h, finetune=finetune)\n",
    "        h = F.relu(h)\n",
    "        y = h + x\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "euDbOQWT1UA8"
   },
   "source": [
    "**Loss classes (45 points)**  \n",
    "In the following cell, you will implement the loss classes.  \n",
    "*Tasks*  \n",
    "- (1) You are provided with a custom VGG-16 implementation. How does it differ than the original implementation? Why can we get away with using the simpler implementation? (**5 points**)\n",
    "- (2) Implement the missing convolution layer of the total variation loss by filling in the missing code. (**10 points**)\n",
    "- (3) Implement the forward pass of the total variation loss by filling in the missing code. (**10 points**)\n",
    "- (4) Implement the feature loss component in the forward pass of the loss function by filling in the missing code. (**10 points**)\n",
    "- (5) Explain why the loss components are scaled. (**5 points**)\n",
    "- (6) Explain why the target features are extracted in test mode. (**5 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9DqHGhS_1M_x"
   },
   "outputs": [],
   "source": [
    "class Vgg4Layers(Chain):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Vgg4Layers, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.conv1_1 = L.Convolution2D( 3, 64, 3, pad = 1)\n",
    "            self.conv1_2 = L.Convolution2D( 64, 64, 3, pad = 1)\n",
    "            self.conv2_1 = L.Convolution2D( 64, 128, 3, pad = 1)\n",
    "            self.conv2_2 = L.Convolution2D(128, 128, 3, pad = 1)\n",
    "\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.mean = (np.array([[[[103.939]], [[116.779]], [[123.68]]]]), 'float32')\n",
    "        self.register_persistent('mean')\n",
    "        \n",
    "        h = x - F.broadcast_to(self.mean, x.shape)\n",
    "        h = self.convolution2D_0(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_1(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.max_pooling_2d(h, 2, 2)\n",
    "        h = self.convolution2D_2(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_3(h)\n",
    "        y = F.relu(h)\n",
    "\n",
    "        return y\n",
    "\n",
    "class TotalVariationLoss(Chain):\n",
    "    def __init__(self):\n",
    "        super(TotalVariationLoss, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            convolution2D_0 = L.Convolution2D(3, 1, 2, nobias = True, initialW = np.array([3 * [[[-1], [1]]]], 'float32'))\n",
    "            # (2) start\n",
    "            convolution2D_1 = L.Convolution2D(3, 1, 2, nobias = True, initialW = np.array([3 * [[[-1, 1]]]], 'float32'))\n",
    "            # (2) end\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = self.convolution2D_0(x)\n",
    "        h = np.square(h)\n",
    "        \n",
    "        h1 = self.convolution2D_1(x)\n",
    "        h1 = np.square(h1)\n",
    "        \n",
    "        y = np.sqrt(np.sum(h1, h))\n",
    "        return y\n",
    "\n",
    "class LossFunction(object):\n",
    "    def __init__(self, lambda_):\n",
    "        self.totalVariationLoss = TotalVariationLoss()\n",
    "        self.vgg4Layers         = Vgg4Layers()\n",
    "\n",
    "    def __call__(t, y):            \n",
    "        with chainer.using_config('train', False):\n",
    "            t_ = self.vgg4Layers(t)\n",
    "\n",
    "        # (4) start\n",
    "        y_ = self.vgg4Layers(y)\n",
    "        feature_loss = chainer.functions.mean_squared_error(t_, y_)\n",
    "        # (4) end\n",
    "        pixel_loss = lambda_['pixel'] * F.mean_squared_error(t , y) \n",
    "        total_variation_loss = lambda_['total_variation'] * self.totalVariationLoss(y)\n",
    "        loss = feature_loss + pixel_loss + total_variation_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "# (1) The VGG-4 has only 4 layers instead of the 16 layers in the origional VGG-16\n",
    "# (5) Write your answer here.\n",
    "# (6) Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_nGcCNEy8p3g"
   },
   "source": [
    "**Initialization (10 points)**  \n",
    "The following cell initializes the loss function, the loss history, the model, the optimizer, the datasets and the iterators. *You do not have to make any changes to the code.*  \n",
    "*Tasks*\n",
    "- (1) Study the code and refer to the chainer docuimentation if anything is unclear. You will be expected to write similar code by yourself in the coming practicals. (**0 points**)  \n",
    "- (2) What are the boolean arguments that are passed to the SerialIterator class? (**5 points**)  \n",
    "- (3) Why is it false for the training iterator but not for other iterators? In other words, what would happen if we were to set it to false for the training iterator and true for the other iterators? (**5 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAa-KI4W-3Mm"
   },
   "outputs": [],
   "source": [
    "lossFunction = LossFunction(lambda_)\n",
    "load_npz('{:s}/Vgg4Layers.npz'.format(model_directory), lossFunction.vgg4Layers)\n",
    "loss_history = {'training': [], 'validation': []}\n",
    "model = Model(1, outsize) if device < 0 else Model(1, outsize).to_gpu(device)\n",
    "optimizer = Adam()\n",
    "\n",
    "optimizer.setup(model)\n",
    "\n",
    "data_file = sorted(glob('{}/*.jpg'.format(data_directory)))\n",
    "training_set = Dataset(data_file[:int(.64 * len(data_file))])\n",
    "validation_set = Dataset(data_file[int(.64 * len(data_file)) : int(.8 * len(data_file))])\n",
    "\n",
    "#pprint(vars(validation_set))\n",
    "\n",
    "test_set = Dataset(data_file[int(.8 * len(data_file)) :])\n",
    "training_iterator = iterators.SerialIterator(training_set, batch_size, False, True)\n",
    "validation_iterator = iterators.SerialIterator(validation_set, batch_size, False, False)\n",
    "test_iterator = iterators.SerialIterator(test_set , batch_size, False, False)\n",
    "\n",
    "# (2) repeat defines whether or not the iterator starts again after iterating over all the examples. \n",
    "#     shuffle is used to iterate over the examples in a random order.\n",
    "# (3) During the testing and validation process, you want to be able to reproduce the results. Therefore shuffle\n",
    "#     should be set to False. During the training process, it is better to shuffle the examples so that the model\n",
    "#     does not overfit according to patterns in the examples' sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAKIEbqPFzsc"
   },
   "source": [
    "**Training and validation (20 points)**  \n",
    "In the following cell, you will train and validate your model.\n",
    "*Tasks*   \n",
    "- (1) Implement training loss estimation, backprop and parameter update. (**10 points**)\n",
    "- (2) Implement validation loss history (**5 points**)\n",
    "- (3) Implement model serialization  (**5 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-pOSKTw0tcK"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-675752f9c48a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mchainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musing_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[1;31m# (1) start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-168-16d13b2650d2>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, finetune)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinetune\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolution2D_11\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchNormalization_11\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinetune\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolution2D_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    loss_history['training'].append(0)\n",
    "\n",
    "    for j, batch in enumerate(training_iterator):\n",
    "        with chainer.using_config('train', True):\n",
    "            t, x = concat_examples(batch, device)\n",
    "            y = model(x)\n",
    "            # (1) start\n",
    "            loss = lossFunction(t, y)\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.update()\n",
    "            # (1) end\n",
    "\n",
    "        loss_history['training'][-1] += float(loss.data)\n",
    "\n",
    "    loss_history['training'][-1] /= j + 1\n",
    "    # (2) start\n",
    "    loss_history['validation'].append(0)\n",
    "\n",
    "    for j, batch in enumerate(validation_iterator):\n",
    "        with chainer.using_config('train', False):\n",
    "            t, x = concat_examples(batch, device)\n",
    "            y = model(x)\n",
    "            loss = lossFunction(t, y)\n",
    "\n",
    "        loss_history['validation'][-1] += float(loss.data)\n",
    "\n",
    "    loss_history['validation'][-1] /= j + 1\n",
    "    # (2) end\n",
    "    print('epoch: {:3d} / {:03d}, training loss: {:.4f}, validation loss: {:.4f}.'.format(i + 1, epochs, loss_history['training'], loss_history['validation']))\n",
    "    np.savez('{:s}/loss_history_{:03d}.npz'.format(model_directory, epoch), loss_history)\n",
    "    # (3) start\n",
    "    save_npz('group24.model', model)\n",
    "    # (3) end\n",
    "    save_npz('{:s}/optimizer_{:03d}.npz'.format(model_directory, epoch), optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7YivB1PQ7Obh"
   },
   "source": [
    "**Test (45 points + 15 bonus points)**  \n",
    "In the following cell, you will test your model.  \n",
    "*Tasks*\n",
    "- (1) Estimate the test loss, print it and save it. (**15 points**)\n",
    "- (2) Estimate the validation metrics, print them and save them (tip: scikit-image) (**15 bonus points**)\n",
    "- (3) Plot example results (i.e., plot a few t, x and y) (**10 points**)\n",
    "- (4) Dicuss your implementation in 300 - 350 words (e.g., how good your results are, how you can improve your model, etc.) (**20 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdlnCFDS-Cdh"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-166-0eb119be6f59>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-166-0eb119be6f59>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    for k, batch in enumerate(test_iterator):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# (1), (2) and (3) start\n",
    "for k, batch in enumerate(test_iterator):\n",
    "    with chainer.using_config('train', False):\n",
    "        t, x = concat_examples(batch, device)\n",
    "        y = model(x)\n",
    "        loss = lossFunction(t, y)\n",
    "# (1), (2) and (3) end\n",
    "\n",
    "# (4) Write your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "weeks_2_and_3_assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
